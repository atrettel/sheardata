% Copyright (C) 2020-2022 Andrew Trettel
%
% SPDX-License-Identifier: CC-BY-4.0
\chapter{Design of the database}
\label{chp:design}


\section{Project goals}

The primary goal of this project is to create a single SQLite database that
contains data from as many different shear layer experiments and simulations as
possible.  The data should include uncertainties where possible, and the
project should also concentrate on ensuring that the data remain accessible and
understandable in the long term.  The secondary goal is to create a report
documenting the database and the data itself.  This report serves as a data and
literature review for many different flow classes (a meta-analysis of sorts).

Using this database, it should be possible to ask many different questions
about various kinds of flows directly, without requiring additional
experimentation or simulation.  It also should reveal gaps in current
knowledge, to inform new directions for research.  Lastly, the database would
be valuable for the validation of new models, theories, and numerical codes.


\section{Design goals}

\begin{itemize}

\item The database MUST use SQLite as the database backend.  The primary goal
here is to ensure that it is possible to use SQL commands to select and find
data.  The secondary goal is to emphasize achival quality and long-term access
to the data.  SQLite acts as an open standard that should be supported for
decades.

\item The database MUST include some form of uncertainty quantification (at
least standard uncertainties).

\item The database MUST store the data as generic records with identifiers,
with each data point in a flow merely being a record in a particular table
depending on the category of the data.  This choice keeps the database scheme
static and it differs with a ``spreadsheet''-style design, with separate
columns for each relevant quantity or averaging system.  This choice offers
much more flexiblity, since it allows for scalability.  The database can then
support the addition of many different quantities and averaging systems without
having to change the database schema.

\item Similarly, the database SHOULD data over structure, since data is mutable
(or at least more easily mutable).  It is important to realize that much of
what can be considered ``structure'' here really is ``data''.  For example, a
quantity is not just a column name or some hard-coded location for certain
types of data.  It is data itself, with associated bounds, symbols, and
definitions.

\item The database SHOULD group flow data into 4 main categories:

    \begin{enumerate}

    \item study data (data that applies to an entire case or study),

    \item series data (data that applies to a series of profiles, like drag
    coefficients, etc.),

    \item station data (data that applies to a single profile, like the
    momentum thickness), and

    \item point data (data that applies to a single point in a flow, like the
    local unweighted averaged velocity).

    \end{enumerate}

\item The database SHOULD eliminate redundancy in the tables as much as
possible.  Each data point SHOULD have one and only one location whenever
possible.  The goal here is to reduce or possibly eliminate any potential
contradictions in the data.  Database normalization practices help achieve this
goal.

Note that there is some difficulty in achieving this goal absolutely.  For
example, the database can include both mass density and specific volume, and it
is possible that the corresponding entries may not be inverses, though this can
be checked.  Also, for some flow types, like Couette flow, the flow
classification scheme offers some redundancy, since the flow class already
specifies the wall velocity and therefore the flow classification itself offers
redundant information.

\item Similarly, the database MUST validate the data.  SQL \texttt{CHECK}
contraints and assertions in any Python code are only a start.

\item The database MUST include any supplemental data that may affect the flow
results.  This supplemental data includes information about the experimental or
numerical facilities, the instrumentation or methods used to measure or
calculate values, and any relevant literature sources or documentation.

\end{itemize}


\section{Low-level details}

As discussed above, the database does not represent the data as it would appear
in a spreadsheet or CSV file, where each column represents a different
quantity.  Instead, the database presents the data as a series of ``records'',
with the number of columns being static.  A different column identifies the
quantity being used for a given record.

\begin{table}[htb]
    \centering
    \footnotesize
    \begin{tabular}{ r | r r }
        \texttt{point\_id} & \texttt{y} & \texttt{U} \\
        \hline
                         1 &        0.0 &        0.0 \\
                         2 &        1.0 &        0.5 \\
                         3 &        2.0 &        0.7 \\
                         4 &        3.0 &        0.8 \\
                         5 &        4.0 &        0.9 \\
                         6 &        5.0 &        1.0
    \end{tabular}
    \caption{Flow data presented as a spreadsheet}
    \label{tab:flow-data-spreadsheet}
\end{table}

\begin{table}[htp]
    \centering
    \footnotesize
    \begin{tabular}{ r r | r r }
        \texttt{point\_id} & \texttt{quantity\_id} & \texttt{point\_value} \\
        \hline
                         1 & \texttt{y}            &                   0.0 \\
                         2 & \texttt{y}            &                   1.0 \\
                         3 & \texttt{y}            &                   2.0 \\
                         4 & \texttt{y}            &                   3.0 \\
                         5 & \texttt{y}            &                   4.0 \\
                         6 & \texttt{y}            &                   5.0 \\
                         1 & \texttt{U}            &                   0.0 \\
                         2 & \texttt{U}            &                   0.5 \\
                         3 & \texttt{U}            &                   0.7 \\
                         4 & \texttt{U}            &                   0.8 \\
                         5 & \texttt{U}            &                   0.9 \\
                         6 & \texttt{U}            &                   1.0
    \end{tabular}
    \caption{Flow data presented as records}
    \label{tab:flow-data-records}
\end{table}

Table \ref{tab:flow-data-spreadsheet} depicts some made-up shear flow data as a
spreadsheet and table \ref{tab:flow-data-records} depicts the same data as a
series of records.  Admitted, the spreadsheet-like representation is more
compact and easier to read --- especially since so much data in fluid dynamics
is represented in a columnar manner, including profile data --- but the
record-like representation is scalable and more flexible.  It is also possible
to recover a spreadsheet-like representation using the following SQL query:
%
\begin{lstlisting}[language=SQL]
SELECT y.point_id, y.point_value, u.point_value
FROM (
    SELECT point_id, point_value
    FROM point_values
    WHERE quantity_id='y'
) as y, (
    SELECT point_id, point_value
    FROM point_values
    WHERE quantity_id='U'
) as u
WHERE y.point_id = u.point_id
ORDER BY y.point_id;
\end{lstlisting}

The scalability problem emerges when attempting to add additional data.
Suppose that additional temperature data is also available.  Adding this data
to the database is simple in both cases, though the different operations made
have different costs.  In the spreadsheet-like representation, only another
column must be added.  In the record-like representation, only some additional
entries must be added.  However, adding columns is a more difficult operation
than adding entries.  Now consider having to differentiate between unaveraged
values, averaged values, and density-weighted averaged values for \texttt{y}
and \texttt{U}.  That addition would require many additional columns in a
spreadsheet-like representation but only one more column in the record-like
representation.  Lastly, consider keeping track of what instrument was used to
measure each value and for each averaging system.  For the spreadsheet-like
record, this requires doubling the number of columns, but for the record-like
representation it requires only adding more one column.  Therefore a
record-like representation scales better: it is easier to re-factor and
maintain as the database grows, the requirements change, or the granularity of
the data increases.

The flexibility problem emerges when there are missing values.  Consider, for
example, that the temperature and velocity are not measured at the same points.
For the spreadsheet-like representation, there would need to be many null
values added, but for the record-like representation, there would be no null
values needed, since only the existence of data needs to be recorded, not its
absense.  Conversely, the flexibility allows for multiple values for a given
quantity as well.  For example, consider a study that measures the flow
velocity using different instruments.  A record-like representation allows for
all of this data to be used rather than having to shoehorn in a single
quantity.

Lastly, the record-like representation allows for additional parameters for a
given quantity, like its bounds, to be data in the database itself, rather than
hardcoded as SQL \texttt{CHECK} constraints.  This choice makes more data
available to the user, in other words, and allows these values to be changed
without changing the database schema.


\section{High-level details}

Unlike previous databases, this database does not store flow data as profiles
(like a spreadsheet) or as ``header'' data.  Instead, it organizes flow data
into four categories: study data, series data, station data, and point data.
Each piece of data is stored as a single record in one of those four
categories.

Studies are the primary level of categorization.  Each study is a series of
observations by a research group, like a paper or a set of related papers.
Studies contain series, series contain stations, and stations contain points.
Series refer to a particular flow field in its entirety, like the entire flow
field around an object, or an entire set of boundary layer profiles.  Stations
refer to a single profile in space at specified streamwise and spanwise
coordinates.  And finally, points refer to particular data points in space with
all three coordinates specified.

Different quantities only exist within different categories of data.  For
example, consider the flow around an object.  The drag coefficient is a series
quantity, the boundary layer thickness is a station quantity, and the
streamwise velocity is a point quantity.  Some quantities only exist at walls,
like the skin friction coefficient, but since there could be multiple walls (as
in internal flows) these quantities are stored as point data, though in many
cases they can be identified uniquely by specifying the station.

To locate records in the database, each category of data is assigned a unique
identifier of the following form: flow class (1 letter, described in section
\ref{sec:flow-classification}), year (4 digits), study number (3 digits),
series number (3 digits), station number (3 digits), and point number (4
digits).  Only the first three are needed to identify a study.  For example,
\texttt{D-1914-001} is a study identifier.  \texttt{D-1911-001-005-001-0013} is
a point identifier.  The dashes are used for readability but not stored in the
database.  Using these kind of identifiers, it is possible to uniquely find
data in the database.  Note that the identifiers are systematic: the point
identifier specifies the study, series, and station it belongs to.

\begin{table}[htb]
    \centering
    \footnotesize
    \begin{tabular}{ l | l l l }
        Category              & Classification              & Values                           & Overview chapter \\
        \hline
        \texttt{fluids}      & \texttt{phases}              & \texttt{fluid\_property\_values} & \ref{chp:overview-fluids} \\
        \texttt{facilities}  & \texttt{facility\_classes}   & \texttt{facility\_values}        & \ref{chp:overview-facilities} \\
        \texttt{instruments} & \texttt{instrument\_classes} & \texttt{instrument\_values}      & \ref{chp:overview-instruments} \\
        \texttt{studies}     & \texttt{flow\_classes}       & \texttt{study\_values}           & \ref{chp:overview-studies} \\
        \texttt{series}      & None                         & \texttt{series\_values}          & \ref{chp:overview-studies} \\
        \texttt{stations}    & None                         & \texttt{station\_values}         & \ref{chp:overview-studies} \\
        \texttt{points}      & None                         & \texttt{point\_values}           & \ref{chp:overview-studies}
    \end{tabular}
    \caption{Database tables organized by data category}
    \label{tab:database-tables}
\end{table}

But the database does not store only flow data.  Table
\ref{tab:database-tables} lists all of the categories of data that the database
stores.  Other tables store supplemental data on the fluids, facilities and
instruments used in the studies.  Facilities are the ``venues'' used for the
creation of data, like the wind tunnel or numerical code used.  Instruments are
the means to gather data, like a Pitot tube or a calculation procedure.  For
the sake of completeness, the database can include data on these when
available.

